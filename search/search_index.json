{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Welcome to the world of DevSecOps! You have heard of DevOps. Nowadays, DevSecOps is becoming more popular. How can Security organizations enable developers build security into their products and services? In this workshop, you will experience how tooling and automation can create a security conscious culture throughout the development lifecycle while scaling to the demands of the business. We will see an example of how to stop code that erroneously contains stray AWS credentials (we revoked them first, of course) from being deployed. Level : Intermediate Duration : 2 hours AWS CAF : Security Perspective Prerequisites : AWS Account, Admin IAM User Scenario For this workshop, you will build a pipeline using AWS CodePipeline and AWS Lambda. S3 will be your code repository. Your developers want to deploy an AWS Cloudformation template. However, you need to ensure it is secure before it is released to production. Region Please use the us-west-2 (Oregon) region for this workshop.","title":"Overview"},{"location":"#overview","text":"Welcome to the world of DevSecOps! You have heard of DevOps. Nowadays, DevSecOps is becoming more popular. How can Security organizations enable developers build security into their products and services? In this workshop, you will experience how tooling and automation can create a security conscious culture throughout the development lifecycle while scaling to the demands of the business. We will see an example of how to stop code that erroneously contains stray AWS credentials (we revoked them first, of course) from being deployed. Level : Intermediate Duration : 2 hours AWS CAF : Security Perspective Prerequisites : AWS Account, Admin IAM User","title":"Overview"},{"location":"#scenario","text":"For this workshop, you will build a pipeline using AWS CodePipeline and AWS Lambda. S3 will be your code repository. Your developers want to deploy an AWS Cloudformation template. However, you need to ensure it is secure before it is released to production.","title":"Scenario"},{"location":"#region","text":"Please use the us-west-2 (Oregon) region for this workshop.","title":"Region"},{"location":"01-environment-setup/","text":"Module 1: Environment build If you are doing this workshop at an event, you will be provided with either an AWS account or a hash key for event engine. Please raise your hand and flag down a workshop facilitator for assistance on any issues during the lab. Are you using your own AWS account or given one at a sponsored event? If you are at an AWS Sponsored event, skip down to the Build Phase. If you are using your own AWS account follow these steps: Download or Clone: https://github.com/aws-samples/secure-pipelines-in-aws-workshop Log in with an Adminstrator level account Create an s3 bucket in the US-West-2 Oregon region. Upload the two zip files to that bucket. Go to Cloudformation and run \u201cpipeline.yml\u201d Change the bucket location to the one you created earlier. This bucket location is to reference the zip files. Deploy the stack. Continue on to the next build phase. Build Phase Once in the AWS Console, go to S3 buckets. Look for a bucket: \u201c{CloudformationStackName}-artifactstorebucket-{randomstring} Copy the two zip files into the S3 bucket (remember to copy the zip files, not the unzipped directories) Browse to the CodePipeline console. You will find a new Pipeline called DevSecOps. Click on DevSecOps, and then if the pipeline is not already processing, click on \u201cRelease Change\u201d. You should see the pipeline fail in the TestDeployment stage. This is because you will need to input the correct VPCs. Your environment is now built with a basic pipeline using s3 as the source repository. The error message is part of your next exercise. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 1:  Environment Build"},{"location":"01-environment-setup/#module-1-environment-build","text":"If you are doing this workshop at an event, you will be provided with either an AWS account or a hash key for event engine. Please raise your hand and flag down a workshop facilitator for assistance on any issues during the lab.","title":"Module 1: Environment build"},{"location":"01-environment-setup/#are-you-using-your-own-aws-account-or-given-one-at-a-sponsored-event","text":"If you are at an AWS Sponsored event, skip down to the Build Phase. If you are using your own AWS account follow these steps: Download or Clone: https://github.com/aws-samples/secure-pipelines-in-aws-workshop Log in with an Adminstrator level account Create an s3 bucket in the US-West-2 Oregon region. Upload the two zip files to that bucket. Go to Cloudformation and run \u201cpipeline.yml\u201d Change the bucket location to the one you created earlier. This bucket location is to reference the zip files. Deploy the stack. Continue on to the next build phase.","title":"Are you using your own AWS account or given one at a sponsored event?"},{"location":"01-environment-setup/#build-phase","text":"Once in the AWS Console, go to S3 buckets. Look for a bucket: \u201c{CloudformationStackName}-artifactstorebucket-{randomstring} Copy the two zip files into the S3 bucket (remember to copy the zip files, not the unzipped directories) Browse to the CodePipeline console. You will find a new Pipeline called DevSecOps. Click on DevSecOps, and then if the pipeline is not already processing, click on \u201cRelease Change\u201d. You should see the pipeline fail in the TestDeployment stage. This is because you will need to input the correct VPCs. Your environment is now built with a basic pipeline using s3 as the source repository. The error message is part of your next exercise. After you have successfully setup your environment, you can proceed to the next module.","title":"Build Phase"},{"location":"02-first-pipeline-error/","text":"Module 2: Encrypt the EBS Now that your pipeline is built. As a developer, you uploaded the zip files to s3, you committed code into the pipeline. In this module, this example shows what a developer would experience when code does not comply with security requirements. In this particular case, there is a security requirement that EBS volumes must be encrypted. First Pipeline Error It looks like the pipeline has failed at the \"Static Code Analysis\" stage. Click on the \"Details\" link and take a look at the error. Based on the error message, what needs to be changed? Click on the \"i\" next to CFNParsing. Note the location and file this is referencing. Locate the file, resources.json and open it with your favorite editor. Find the issue in the file and change it the value. Rezip the directory with the modified resources.json. The name of the zip file is important and must match the original name. The pipeline is looking for that filename specifically. Upload and overwrite the existing zip file in: \u201c{CloudformationStackName}-artifactstorebucket-{randomstring} Go back to your CodePipeline screen and watch the stages go through processing again. If you fixed the code correctly, it should go through to the next stage. When it gets to the ApproveTestStack stage, click on the Review button and then approve the deployment. (Normally you would get an email asking for manual approval, but for the purposes of this lab, do not wait). Everything should then carry on until you have a pipeline full of stages which have succeeded. (Optional) Feel free to click on some Details icons to look into what happened at each stage in more detail. CFNParsing is a lambda function is a script which does various checks for security compliance.","title":"Module 2:  Encrypt the EBS"},{"location":"02-first-pipeline-error/#module-2-encrypt-the-ebs","text":"Now that your pipeline is built. As a developer, you uploaded the zip files to s3, you committed code into the pipeline. In this module, this example shows what a developer would experience when code does not comply with security requirements. In this particular case, there is a security requirement that EBS volumes must be encrypted.","title":"Module 2: Encrypt the EBS"},{"location":"02-first-pipeline-error/#first-pipeline-error","text":"It looks like the pipeline has failed at the \"Static Code Analysis\" stage. Click on the \"Details\" link and take a look at the error. Based on the error message, what needs to be changed? Click on the \"i\" next to CFNParsing. Note the location and file this is referencing. Locate the file, resources.json and open it with your favorite editor. Find the issue in the file and change it the value. Rezip the directory with the modified resources.json. The name of the zip file is important and must match the original name. The pipeline is looking for that filename specifically. Upload and overwrite the existing zip file in: \u201c{CloudformationStackName}-artifactstorebucket-{randomstring} Go back to your CodePipeline screen and watch the stages go through processing again. If you fixed the code correctly, it should go through to the next stage. When it gets to the ApproveTestStack stage, click on the Review button and then approve the deployment. (Normally you would get an email asking for manual approval, but for the purposes of this lab, do not wait). Everything should then carry on until you have a pipeline full of stages which have succeeded. (Optional) Feel free to click on some Details icons to look into what happened at each stage in more detail. CFNParsing is a lambda function is a script which does various checks for security compliance.","title":"First Pipeline Error"},{"location":"03-No-AWS-Secrets/","text":"Module 3: No AWS Keys Allowed! In this module, as a Security engineer, you will add a lambda function that will look for AWS Access and Secret keys. Setting Lambda to Look for AWS Credentials Browse to the Lambda console, and create a new function from scratch. Be sure to select the Python 2.7 runtime, and the module*PipelineLambdaRole- IAM Role. Name the function to your choosing. Create function. Set the Lambda time out to 1 minute. cfn_secrets.py is provided in the workshop. Open this in your favorite editor. Paste the contents of cfn_secrets.py source editor (the one in the Lambda console), overwriting the initial placeholder function. Browse back to the CodePipeline Console, and open your DevSecOps Pipeline again. Edit the pipeline, using the button at the top right. Use the Edit Stage button for the StaticCodeAnalysis stage. Select the Edit icon for the CFNParsing function. Copy the contents of \u201cUser Parameters (optional)\u201d to your paste buffer. Close the Edit action pop-up. Add a new action group. Select \u201cAdd action group\u201d. Create a name for your key-scanning action, choose AWS Lambda from the Action provider drop-down. In \u201cFunction name\u201d, select the name you gave your Lambda function in Step 2 above. TemplateSource in the \u201cInput artifacts\u201d drop-down. Paste the contents of your paste buffer from above into \u201cUser Parameters (optional)\u201d Select Save the newly-edited pipeline. You must check the \u201cNo resource updates needed for this source action change\u201d option on the pipeline save pop-up window. Your new Lambda function is now integrated into your pipeline. Proceed to the next module to test your Lambda function.","title":"Module 3:  No AWS Keys"},{"location":"03-No-AWS-Secrets/#module-3-no-aws-keys-allowed","text":"In this module, as a Security engineer, you will add a lambda function that will look for AWS Access and Secret keys.","title":"Module 3: No AWS Keys Allowed!"},{"location":"03-No-AWS-Secrets/#setting-lambda-to-look-for-aws-credentials","text":"Browse to the Lambda console, and create a new function from scratch. Be sure to select the Python 2.7 runtime, and the module*PipelineLambdaRole- IAM Role. Name the function to your choosing. Create function. Set the Lambda time out to 1 minute. cfn_secrets.py is provided in the workshop. Open this in your favorite editor. Paste the contents of cfn_secrets.py source editor (the one in the Lambda console), overwriting the initial placeholder function. Browse back to the CodePipeline Console, and open your DevSecOps Pipeline again. Edit the pipeline, using the button at the top right. Use the Edit Stage button for the StaticCodeAnalysis stage. Select the Edit icon for the CFNParsing function. Copy the contents of \u201cUser Parameters (optional)\u201d to your paste buffer. Close the Edit action pop-up. Add a new action group. Select \u201cAdd action group\u201d. Create a name for your key-scanning action, choose AWS Lambda from the Action provider drop-down. In \u201cFunction name\u201d, select the name you gave your Lambda function in Step 2 above. TemplateSource in the \u201cInput artifacts\u201d drop-down. Paste the contents of your paste buffer from above into \u201cUser Parameters (optional)\u201d Select Save the newly-edited pipeline. You must check the \u201cNo resource updates needed for this source action change\u201d option on the pipeline save pop-up window. Your new Lambda function is now integrated into your pipeline. Proceed to the next module to test your Lambda function.","title":"Setting Lambda to Look for AWS Credentials"},{"location":"04-find-aws-keys/","text":"Module 4: Finding AWS Keys Unfortunately, not all code committed into a source repository will be free of secrets. In this module, as a developer, you will see what security automation can do to help keep confidential information such as AWS keys stay out of source repositories. Release change to start the code building again on the updated pipeline. Oops \u2013 the code had some stray AWS credentials in it \u2013 but this time we\u2019ve caught them and stopped the build! Remove the credentials. Edit resource.json and remove the offending credentials. Rezip the \u201ccodepipe-AWS-devsecops.zip\u201d (the exact name is important) Upload the zip to s3. Come back to the DevSecOps pipeline and watch it through the stages again. Can you use IAM roles instead?","title":"Module 4:  Find AWS Keys"},{"location":"04-find-aws-keys/#module-4-finding-aws-keys","text":"Unfortunately, not all code committed into a source repository will be free of secrets. In this module, as a developer, you will see what security automation can do to help keep confidential information such as AWS keys stay out of source repositories. Release change to start the code building again on the updated pipeline. Oops \u2013 the code had some stray AWS credentials in it \u2013 but this time we\u2019ve caught them and stopped the build! Remove the credentials. Edit resource.json and remove the offending credentials. Rezip the \u201ccodepipe-AWS-devsecops.zip\u201d (the exact name is important) Upload the zip to s3. Come back to the DevSecOps pipeline and watch it through the stages again. Can you use IAM roles instead?","title":"Module 4:  Finding AWS Keys"},{"location":"05-missing-s3-confg/","text":"Module 5: Missing s3 Configuration In this module, as part of security governance, all s3 buckets must have s3 versioning configuration enabled. This policy helps organizations recover from deletion or alterations of data by keeping copies of previous versions. As a security engineer, you want to enable the pipeline to enforce enabling s3 bucket versioning configuration. Setting Lambda to scan AWS Cloudformation templates for s3 configuration settings Browse to the Lambda console, and create a new function from scratch. Be sure to select the Python 2.7 runtime, and the module*PipelineLambdaRole- IAM Role. Name the function to your choosing. Create function. Set the Lambda time out to 1 minute. cfn_s3_versioning.py is provided in the workshop. Open this in your favorite editor. Paste the contents of cfn_s3_versioning.py source editor (the one in the Lambda console), overwriting the initial placeholder function. Browse back to the CodePipeline Console, and open your DevSecOps Pipeline again. Edit the pipeline, using the button at the top right. Use the Edit Stage button for the StaticCodeAnalysis stage. Select the Edit icon for the CFNParsing function. Copy the contents of \u201cUser Parameters (optional)\u201d to your paste buffer. Close the Edit action pop-up. Add a new action group. Select \u201cAdd action group\u201d. Create a name for your key-scanning action, choose AWS Lambda from the Action provider drop-down. In \u201cFunction name\u201d, select the name you gave your Lambda function in Step 2 above. TemplateSource in the \u201cInput artifacts\u201d drop-down. Paste the contents of your paste buffer from above into \u201cUser Parameters (optional)\u201d Select Save the newly-edited pipeline. You must check the \u201cNo resource updates needed for this source action change\u201d option on the pipeline save pop-up window. Your new Lambda function is now integrated into your pipeline. Proceed to the next module to test your Lambda function. What other things can you look for in an AWS Cloudformation template which you can create a security automation?","title":"Module 5:  Missing S3 Configuration"},{"location":"05-missing-s3-confg/#module-5-missing-s3-configuration","text":"In this module, as part of security governance, all s3 buckets must have s3 versioning configuration enabled. This policy helps organizations recover from deletion or alterations of data by keeping copies of previous versions. As a security engineer, you want to enable the pipeline to enforce enabling s3 bucket versioning configuration.","title":"Module 5:  Missing s3 Configuration"},{"location":"05-missing-s3-confg/#setting-lambda-to-scan-aws-cloudformation-templates-for-s3-configuration-settings","text":"Browse to the Lambda console, and create a new function from scratch. Be sure to select the Python 2.7 runtime, and the module*PipelineLambdaRole- IAM Role. Name the function to your choosing. Create function. Set the Lambda time out to 1 minute. cfn_s3_versioning.py is provided in the workshop. Open this in your favorite editor. Paste the contents of cfn_s3_versioning.py source editor (the one in the Lambda console), overwriting the initial placeholder function. Browse back to the CodePipeline Console, and open your DevSecOps Pipeline again. Edit the pipeline, using the button at the top right. Use the Edit Stage button for the StaticCodeAnalysis stage. Select the Edit icon for the CFNParsing function. Copy the contents of \u201cUser Parameters (optional)\u201d to your paste buffer. Close the Edit action pop-up. Add a new action group. Select \u201cAdd action group\u201d. Create a name for your key-scanning action, choose AWS Lambda from the Action provider drop-down. In \u201cFunction name\u201d, select the name you gave your Lambda function in Step 2 above. TemplateSource in the \u201cInput artifacts\u201d drop-down. Paste the contents of your paste buffer from above into \u201cUser Parameters (optional)\u201d Select Save the newly-edited pipeline. You must check the \u201cNo resource updates needed for this source action change\u201d option on the pipeline save pop-up window. Your new Lambda function is now integrated into your pipeline. Proceed to the next module to test your Lambda function. What other things can you look for in an AWS Cloudformation template which you can create a security automation?","title":"Setting Lambda to scan AWS Cloudformation templates for s3 configuration settings"},{"location":"06-s3-versioning/","text":"Module 6: Configuring S3 Security Many organizations utilize s3 extensively. It is important that the s3 buckets are configured to the organization's requirements to ensure data stored safely. Now that you have added a lambda function to enforce enablement of S3 Versioning Configuration. Release the change to start the pipeline. What is S3 Versioning? How can it help you secure data? Add the appropriate configuration. Edit resource.json and remove the offending credentials. Rezip the \u201ccodepipe-AWS-devsecops.zip\u201d (the exact name is important) Upload the zip to s3. Come back to the DevSecOps pipeline and watch it through the stages again. Hint: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html Are there other s3 configurations you would want to enforce? Are there other AWS native ways to enforce some of those controls?","title":"Module 6:  Configuring S3 Security"},{"location":"06-s3-versioning/#module-6-configuring-s3-security","text":"Many organizations utilize s3 extensively. It is important that the s3 buckets are configured to the organization's requirements to ensure data stored safely. Now that you have added a lambda function to enforce enablement of S3 Versioning Configuration. Release the change to start the pipeline. What is S3 Versioning? How can it help you secure data? Add the appropriate configuration. Edit resource.json and remove the offending credentials. Rezip the \u201ccodepipe-AWS-devsecops.zip\u201d (the exact name is important) Upload the zip to s3. Come back to the DevSecOps pipeline and watch it through the stages again. Hint: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html Are there other s3 configurations you would want to enforce? Are there other AWS native ways to enforce some of those controls?","title":"Module 6:  Configuring S3 Security"},{"location":"07-cleanup/","text":"Module 7: Cleanup This last module helps with cleaning up the lab environment. This only applies if you are running this in your own account. Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. If you are using this in an instructor led session, with the AWS Event Engine you do not need to run the cleanup steps If you are running this in your own account. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete s3 buckets. Go to Amazon S3 console. Go into the s3 bucket you created in module 1 and delete all of the contents. After the bucket is empty, delete the bucket. Look for artifactstorebucket and delete all of the contents. After the bucket is empty, delete the bucket. Delete the Cloudformation stack. Go to AWS Cloudformation console. Look for the stack deployed in module 1 and delete the stack. Delete Lambdas. Go to the AWS Lambda console. Delete the lambda functions you created. Finished! Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like. Continuing On The workshop is intended to give you an idea of how to start your own Security","title":"Module 7:  Cleaning Up"},{"location":"07-cleanup/#module-7-cleanup","text":"This last module helps with cleaning up the lab environment. This only applies if you are running this in your own account.","title":"Module 7: Cleanup"},{"location":"07-cleanup/#cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. If you are using this in an instructor led session, with the AWS Event Engine you do not need to run the cleanup steps If you are running this in your own account. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Delete s3 buckets. Go to Amazon S3 console. Go into the s3 bucket you created in module 1 and delete all of the contents. After the bucket is empty, delete the bucket. Look for artifactstorebucket and delete all of the contents. After the bucket is empty, delete the bucket. Delete the Cloudformation stack. Go to AWS Cloudformation console. Look for the stack deployed in module 1 and delete the stack. Delete Lambdas. Go to the AWS Lambda console. Delete the lambda functions you created.","title":"Cleanup"},{"location":"07-cleanup/#finished","text":"Congratulations on completing this workshop! This is the workshop's permanent home, so feel free to revisit as often as you'd like.","title":"Finished!"},{"location":"07-cleanup/#continuing-on","text":"The workshop is intended to give you an idea of how to start your own Security","title":"Continuing On"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"}]}